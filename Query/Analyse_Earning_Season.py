import sqlite3
import json
import os
import datetime
from collections import defaultdict

USER_HOME = os.path.expanduser("~")
BASE_CODING_DIR = os.path.join(USER_HOME, "Coding")

# [å›æµ‹é…ç½®åŒº]
# SYMBOL_TO_TRACE = ""
# TARGET_DATE = ""

SYMBOL_TO_TRACE = "PPG"
TARGET_DATE = "2025-11-06"

LOG_FILE_PATH = os.path.join(USER_HOME, "Downloads", "Season_trace_log.txt")

# --- 1. é…ç½®æ–‡ä»¶å’Œè·¯å¾„ ---
PATHS = {
    "base": BASE_CODING_DIR,
    "news": lambda base: os.path.join(base, "News"),
    "db": lambda base: os.path.join(base, "Database"),
    "config": lambda base: os.path.join(base, "Financial_System", "Modules"),
    "earnings_release_next": lambda news: os.path.join(news, "Earnings_Release_next.txt"),
    "earnings_release_new": lambda news: os.path.join(news, "Earnings_Release_new.txt"),
    "earnings_release_third": lambda news: os.path.join(news, "Earnings_Release_third.txt"),
    "earnings_release_fourth": lambda news: os.path.join(news, "Earnings_Release_fourth.txt"),
    "earnings_release_fifth": lambda news: os.path.join(news, "Earnings_Release_fifth.txt"),
    "sectors_json": lambda config: os.path.join(config, "Sectors_All.json"),
    "db_file": lambda db: os.path.join(db, "Finance.db"),
    "blacklist_json": lambda config: os.path.join(config, "Blacklist.json"),
    "panel_json": lambda config: os.path.join(config, "Sectors_panel.json"),
    "description_json": lambda config: os.path.join(config, 'description.json'),
    "tags_setting_json": lambda config: os.path.join(config, 'tags_filter.json'),
    "earnings_history_json": lambda config: os.path.join(config, 'Earning_History.json'),
    "backup_Strategy12": lambda news: os.path.join(news, "backup", "NextWeek_Earning.txt"),
    "backup_Strategy34": lambda news: os.path.join(news, "backup", "Strategy34_earning.txt"),
}

# åŠ¨æ€ç”Ÿæˆå®Œæ•´è·¯å¾„
base_path = PATHS["base"]
news_path = PATHS["news"](base_path)
db_path = PATHS["db"](base_path)
config_path = PATHS["config"](base_path)

DB_FILE = PATHS["db_file"](db_path)
SECTORS_JSON_FILE = PATHS["sectors_json"](config_path)
BLACKLIST_JSON_FILE = PATHS["blacklist_json"](config_path)
PANEL_JSON_FILE = PATHS["panel_json"](config_path)
DESCRIPTION_JSON_FILE = PATHS["description_json"](config_path)
TAGS_SETTING_JSON_FILE = PATHS["tags_setting_json"](config_path)
EARNING_HISTORY_JSON_FILE = PATHS["earnings_history_json"](config_path)


# --- 2. å¯é…ç½®å‚æ•° --- ä½¿ç”¨ä¸€ä¸ªé…ç½®å­—å…¸æ¥ç®¡ç†æ‰€æœ‰å‚æ•°
CONFIG = {
    # ========================================
    "NUM_EARNINGS_TO_CHECK": 2,
    "MIN_DROP_PERCENTAGE": 0.03,
    "MINOR_DROP_PERCENTAGE": 0.05,
    "MIDDLE_DROP_PERCENTAGE": 0.07,
    "MIDDLE_PLUS_DROP_PERCENTAGE": 0.08,
    "HIGH_DROP_PERCENTAGE": 0.09,
    "MAX_DROP_PERCENTAGE": 0.15,
    "MIN_TURNOVER": 100_000_000,
    "MARKETCAP_THRESHOLD": 100_000_000_000,
    "MAX_RISE_FROM_7D_LOW": 0.06,
}

# --- 3. è¾…åŠ©ä¸æ–‡ä»¶æ“ä½œæ¨¡å— ---

# æ–°å¢: ç”¨äºåŠ è½½å¤–éƒ¨æ ‡ç­¾é…ç½®çš„å‡½æ•°
def load_tag_settings(json_path):
    """ä» Tags_Setting.json åŠ è½½ BLACKLIST_TAGS å’Œ HOT_TAGSã€‚"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            settings = json.load(f)
        
        # ä»JSONåŠ è½½åˆ—è¡¨ï¼Œå¹¶è½¬æ¢æˆsetï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›ç©ºset
        tag_blacklist = set(settings.get('BLACKLIST_TAGS', []))
        hot_tags = set(settings.get('HOT_TAGS', []))
        
        print(f"æˆåŠŸä» {os.path.basename(json_path)} åŠ è½½è®¾ç½®ã€‚")
        print(f"  - BLACKLIST_TAGS: {len(tag_blacklist)} ä¸ª")
        print(f"  - HOT_TAGS: {len(hot_tags)} ä¸ª")
        
        return tag_blacklist, hot_tags
    except FileNotFoundError:
        print(f"è­¦å‘Š: æ ‡ç­¾é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {json_path}ã€‚å°†ä½¿ç”¨ç©ºçš„é»‘åå•å’Œçƒ­é—¨æ ‡ç­¾åˆ—è¡¨ã€‚")
        return set(), set()
    except json.JSONDecodeError:
        print(f"è­¦å‘Š: æ ‡ç­¾é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {json_path}ã€‚å°†ä½¿ç”¨ç©ºçš„é»‘åå•å’Œçƒ­é—¨æ ‡ç­¾åˆ—è¡¨ã€‚")
        return set(), set()
    except Exception as e:
        print(f"è­¦å‘Š: åŠ è½½æ ‡ç­¾é…ç½®å¤±è´¥: {e}ã€‚å°†ä½¿ç”¨ç©ºçš„é»‘åå•å’Œçƒ­é—¨æ ‡ç­¾åˆ—è¡¨ã€‚")
        return set(), set()

def create_symbol_to_sector_map(json_file_path):
    """ä»Sectors_All.jsonåˆ›å»º symbol -> sector çš„æ˜ å°„ã€‚"""
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            sectors_data = json.load(f)
        symbol_map = {symbol: sector for sector, symbols in sectors_data.items() for symbol in symbols}
        print(f"æˆåŠŸåˆ›å»ºæ¿å—æ˜ å°„ï¼Œå…± {len(symbol_map)} ä¸ª symbolã€‚")
        return symbol_map
    except Exception as e:
        print(f"é”™è¯¯: åˆ›å»ºæ¿å—æ˜ å°„å¤±è´¥: {e}")
        return None

def get_symbols_from_file(file_path):
    """ä»æ–‡æœ¬æ–‡ä»¶ä¸­æå–è‚¡ç¥¨ä»£ç ã€‚"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return [line.strip().split(':')[0].strip() for line in f if line.strip()]
    except FileNotFoundError:
        print(f"ä¿¡æ¯: æ–‡ä»¶æœªæ‰¾åˆ° {file_path}ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚")
        return []

def load_blacklist(json_file_path):
    """ä»Blacklist.jsonåŠ è½½'newlow'é»‘åå•ã€‚"""
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        blacklist = set(data.get('newlow', []))
        print(f"æˆåŠŸåŠ è½½ 'newlow' é»‘åå•: {len(blacklist)} ä¸ª symbolã€‚")
        return blacklist
    except Exception as e:
        print(f"è­¦å‘Š: åŠ è½½é»‘åå•å¤±è´¥: {e}ï¼Œå°†ä¸è¿›è¡Œè¿‡æ»¤ã€‚")
        return set()

# æ–°å¢: ç”¨äºåŠ è½½ 'Earning' Symbol é»‘åå•çš„å‡½æ•°
def load_earning_symbol_blacklist(json_path):
    """ä»Blacklist.jsonåŠ è½½'Earning'åˆ†ç»„çš„symbolé»‘åå•ã€‚"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        blacklist = set(data.get('Earning', []))
        print(f"æˆåŠŸåŠ è½½ 'Earning' Symbol é»‘åå•: {len(blacklist)} ä¸ª symbolã€‚")
        return blacklist
    except Exception as e:
        print(f"è­¦å‘Š: åŠ è½½ 'Earning' Symbol é»‘åå•å¤±è´¥: {e}ï¼Œå°†ä¸è¿›è¡Œè¿‡æ»¤ã€‚")
        return set()

# ========== æ–°å¢/ä¿®æ”¹éƒ¨åˆ† 4/5 ==========
def load_symbol_tags(json_path):
    """ä» description.json åŠ è½½ 'stocks' åˆ†ç»„ä¸‹æ‰€æœ‰ symbol çš„ tagsã€‚"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        symbol_tag_map = {}
        stock_list = data.get('stocks', [])
        
        for item in stock_list:
            symbol = item.get('symbol')
            tags = item.get('tag', [])
            if symbol:
                symbol_tag_map[symbol] = tags
        
        print(f"æˆåŠŸä» description.json åŠ è½½ {len(symbol_tag_map)} ä¸ª symbol çš„ tagsã€‚")
        return symbol_tag_map
    except FileNotFoundError:
        print(f"è­¦å‘Š: Tag å®šä¹‰æ–‡ä»¶æœªæ‰¾åˆ°: {json_path}ã€‚å°†ä¸è¿›è¡ŒTagè¿‡æ»¤ã€‚")
        return {}
    except json.JSONDecodeError:
        print(f"è­¦å‘Š: Tag å®šä¹‰æ–‡ä»¶æ ¼å¼é”™è¯¯: {json_path}ã€‚å°†ä¸è¿›è¡ŒTagè¿‡æ»¤ã€‚")
        return {}
    except Exception as e:
        print(f"è­¦å‘Š: åŠ è½½ Tags å¤±è´¥: {e}ã€‚å°†ä¸è¿›è¡ŒTagè¿‡æ»¤ã€‚")
        return {}

def update_json_panel(symbols_list, target_json_path, group_name, symbol_to_note=None):
    """æ›´æ–°JSONé¢æ¿æ–‡ä»¶ã€‚
    symbols_list: list[str] è¦å†™å…¥çš„ symbol åˆ—è¡¨
    group_name: str JSONä¸­çš„ç»„å
    symbol_to_note: Optional[dict[str, str]] å¦‚æœæä¾›ï¼ŒæŒ‰æ˜ å°„å†™å…¥ valueï¼›å¦åˆ™å†™ä¸º ""
    """
    print(f"\n--- æ›´æ–° JSON æ–‡ä»¶: {os.path.basename(target_json_path)} -> '{group_name}' ---")
    try:
        with open(target_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        print(f"ä¿¡æ¯: ç›®æ ‡JSONæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯ï¼Œå°†åˆ›å»ºä¸€ä¸ªæ–°çš„ã€‚")
        data = {}

    if symbol_to_note is None:
        data[group_name] = {symbol: "" for symbol in sorted(symbols_list)}
    else:
        # å¯¹äºåˆ—è¡¨ä¸­æ²¡æœ‰æ˜ å°„çš„ symbolï¼Œé»˜è®¤ç©ºå­—ç¬¦ä¸²
        data[group_name] = {symbol: symbol_to_note.get(symbol, "") for symbol in sorted(symbols_list)}

    try:
        with open(target_json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
        print(f"æˆåŠŸå°† {len(symbols_list)} ä¸ª symbol å†™å…¥ç»„ '{group_name}'.")
    except Exception as e:
        print(f"é”™è¯¯: å†™å…¥JSONæ–‡ä»¶å¤±è´¥: {e}")

def update_earning_history_json(file_path, group_name, symbols_to_add, log_detail):
    """
    æ›´æ–° Earning_History.json æ–‡ä»¶ã€‚
    - file_path: Earning_History.json çš„å®Œæ•´è·¯å¾„ã€‚
    - group_name: 'season' æˆ– 'no_season'ã€‚
    - symbols_to_add: æœ¬æ¬¡è¦æ·»åŠ çš„ symbol åˆ—è¡¨ã€‚
    - log_detail: æ—¥å¿—è®°å½•å‡½æ•°ã€‚
    """
    log_detail(f"\n--- æ›´æ–°å†å²è®°å½•æ–‡ä»¶: {os.path.basename(file_path)} -> '{group_name}' ---")
    yesterday = datetime.date.today() - datetime.timedelta(days=1)  # è·å–æ˜¨å¤©çš„æ—¥æœŸ
    yesterday_str = yesterday.isoformat()  # è·å– 'YYYY-MM-DD' æ ¼å¼çš„æ˜¨å¤©æ—¥æœŸ

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        log_detail("ä¿¡æ¯: å†å²è®°å½•æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯ï¼Œå°†åˆ›å»ºæ–°çš„ã€‚")
        data = {}

    # ç¡®ä¿é¡¶å±‚åˆ†ç»„å­˜åœ¨ (e.g., 'season')
    if group_name not in data:
        data[group_name] = {}

    # è·å–æ˜¨å¤©å·²æœ‰çš„ symbol åˆ—è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸ºç©ºåˆ—è¡¨
    existing_symbols = data[group_name].get(yesterday_str, [])
    
    # åˆå¹¶æ–°æ—§åˆ—è¡¨ï¼Œé€šè¿‡é›†åˆå»é‡ï¼Œç„¶åæ’åº
    combined_symbols = set(existing_symbols) | set(symbols_to_add)
    updated_symbols = sorted(list(combined_symbols))

    # æ›´æ–°æ•°æ®ç»“æ„
    data[group_name][yesterday_str] = updated_symbols
    
    num_added = len(updated_symbols) - len(existing_symbols)

    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
        log_detail(f"æˆåŠŸæ›´æ–°å†å²è®°å½•ã€‚æ—¥æœŸ: {yesterday_str}, åˆ†ç»„: '{group_name}'.")
        log_detail(f"  - æœ¬æ¬¡æ–°å¢ {num_added} ä¸ªä¸é‡å¤çš„ symbolã€‚")
        log_detail(f"  - å½“å¤©æ€»è®¡ {len(updated_symbols)} ä¸ª symbolã€‚")
    except Exception as e:
        log_detail(f"é”™è¯¯: å†™å…¥å†å²è®°å½•æ–‡ä»¶å¤±è´¥: {e}")
        
def get_next_er_date(last_er_date):
    """è®¡ç®—ç†è®ºä¸Šçš„ä¸‹ä¸€æ¬¡è´¢æŠ¥æ—¥æœŸ (+94å¤©)"""
    return last_er_date + datetime.timedelta(days=94)


# --- 4. æ ¸å¿ƒæ•°æ®è·å–æ¨¡å— (å·²é›†æˆè¿½è¸ªå’Œå›æµ‹ç³»ç»Ÿ) ---

def build_stock_data_cache(symbols, db_path, symbol_sector_map, symbol_to_trace, log_detail, target_date=None):
    """
    ä¸ºæ‰€æœ‰ç»™å®šçš„symbolsä¸€æ¬¡æ€§ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰éœ€è¦çš„æ•°æ®ã€‚
    è¿™æ˜¯æ€§èƒ½ä¼˜åŒ–çš„æ ¸å¿ƒï¼Œé¿å…äº†é‡å¤æŸ¥è¯¢ã€‚
    """
    print(f"\n--- å¼€å§‹ä¸º {len(symbols)} ä¸ª symbol æ„å»ºæ•°æ®ç¼“å­˜ ---")
    cache = {}
    conn = sqlite3.connect(db_path, timeout=60.0)
    cursor = conn.cursor()

    # æ£€æŸ¥marketcapåˆ—æ˜¯å¦å­˜åœ¨çš„æ ‡å¿—
    marketcap_exists = True

    for i, symbol in enumerate(symbols):
        is_tracing = (symbol == symbol_to_trace)
        if is_tracing: log_detail(f"\n{'='*20} å¼€å§‹ä¸ºç›®æ ‡ {symbol} æ„å»ºæ•°æ®ç¼“å­˜ {'='*20}")

        data = {'is_valid': False, 'all_er_dates': [], 'latest_er_date_str': '', 'latest_er_date': None, 'all_er_prices': [], 'latest_date_str': '', 'latest_price': 0.0, 'latest_volume': 0.0, 'pe_ratio': None, 'marketcap': None, 'earning_record_price': None}
        table_name = symbol_sector_map.get(symbol)
        if not table_name: continue

        # 1. è·å–è´¢æŠ¥æ—¥æœŸ (å›æµ‹ç§»æ¤ï¼šå¢åŠ æ—¥æœŸä¸Šé™)
        if target_date:
            cursor.execute("SELECT date FROM Earning WHERE name = ? AND date <= ? ORDER BY date DESC LIMIT ?", 
                           (symbol, target_date, CONFIG["NUM_EARNINGS_TO_CHECK"] + 1))
        else:
            cursor.execute("SELECT date FROM Earning WHERE name = ? ORDER BY date DESC LIMIT ?", 
                           (symbol, CONFIG["NUM_EARNINGS_TO_CHECK"] + 1))
        
        earnings_dates = [r[0] for r in cursor.fetchall()]
        if is_tracing: log_detail(f"[{symbol}] æ­¥éª¤1: è·å–è´¢æŠ¥æ—¥æœŸã€‚æ‰¾åˆ° {len(earnings_dates)} ä¸ª: {earnings_dates}")
        
        if len(earnings_dates) < CONFIG["NUM_EARNINGS_TO_CHECK"]:
            if is_tracing: log_detail(f"[{symbol}] å¤±è´¥: è´¢æŠ¥æ¬¡æ•° ({len(earnings_dates)}) å°‘äºè¦æ±‚çš„ {CONFIG['NUM_EARNINGS_TO_CHECK']} æ¬¡ã€‚")
            continue

        data['all_er_dates'] = earnings_dates
        data['latest_er_date_str'] = earnings_dates[0]
        data['latest_er_date'] = datetime.datetime.strptime(earnings_dates[0], "%Y-%m-%d").date()

        # 2. è·å–è¿™äº›è´¢æŠ¥æ—¥çš„æ”¶ç›˜ä»·
        er_prices = []
        prices_valid = True
        for date_str in earnings_dates:
            cursor.execute(f'SELECT price FROM "{table_name}" WHERE name = ? AND date = ?', (symbol, date_str))
            price_result = cursor.fetchone()
            if price_result and price_result[0] is not None:
                er_prices.append(price_result[0])
            else:
                # å…³é”®è´¢æŠ¥æ—¥ä»·æ ¼ç¼ºå¤±ï¼Œä½†ä¸ºäº†ä¿æŒé•¿åº¦ä¸€è‡´ï¼Œå…ˆç”¨Noneå¡«å……
                er_prices.append(None)
        if is_tracing: log_detail(f"[{symbol}] æ­¥éª¤2: è·å–è´¢æŠ¥æ—¥æ”¶ç›˜ä»·ã€‚ä»·æ ¼: {er_prices}")
        
        # æ£€æŸ¥å…³é”®çš„å‰Næ¬¡è´¢æŠ¥ä»·æ ¼æ˜¯å¦å­˜åœ¨
        if any(p is None for p in er_prices[:CONFIG["NUM_EARNINGS_TO_CHECK"]]):
            if is_tracing: log_detail(f"[{symbol}] å¤±è´¥: å‰ {CONFIG['NUM_EARNINGS_TO_CHECK']} æ¬¡è´¢æŠ¥ä¸­å­˜åœ¨ç¼ºå¤±çš„ä»·æ ¼ã€‚")
            continue

        data['all_er_prices'] = er_prices
        
        # 3. è·å–æœ€æ–°äº¤æ˜“æ—¥æ•°æ® (å›æµ‹ç§»æ¤ï¼šæ ¹æ® target_date é”å®šåŸºå‡†æ—¥)
        if target_date:
            cursor.execute(f'SELECT date, price, volume FROM "{table_name}" WHERE name = ? AND date <= ? ORDER BY date DESC LIMIT 1', (symbol, target_date))
        else:
            cursor.execute(f'SELECT date, price, volume FROM "{table_name}" WHERE name = ? ORDER BY date DESC LIMIT 1', (symbol,))
        
        latest_row = cursor.fetchone()
        if not latest_row or latest_row[1] is None or latest_row[2] is None:
            if is_tracing: log_detail(f"[{symbol}] å¤±è´¥: æœªèƒ½è·å–åˆ°æœ‰æ•ˆçš„æœ€æ–°äº¤æ˜“æ—¥æ•°æ®ã€‚æŸ¥è¯¢ç»“æœ: {latest_row}")
            continue
            
        data['latest_date_str'], data['latest_price'], data['latest_volume'] = latest_row
        data['latest_date'] = datetime.datetime.strptime(data['latest_date_str'], "%Y-%m-%d").date()
        if is_tracing: log_detail(f"[{symbol}] æ­¥éª¤3: è·å–æœ€æ–°äº¤æ˜“æ—¥æ•°æ®ã€‚æ—¥æœŸ: {data['latest_date_str']}, ä»·æ ¼: {data['latest_price']}, æˆäº¤é‡: {data['latest_volume']}")

        # 4. è·å–å…¶ä»–æ‰€éœ€æ•°æ® (PE, MarketCap, Earningè¡¨price)
        data['pe_ratio'] = None
        data['marketcap'] = None

        # 4. è·å– PE, å¸‚å€¼ç­‰ (MNSPPè¡¨é€šå¸¸åªå­˜æœ€æ–°ï¼Œå›æµ‹æ—¶ä½œä¸ºå‚è€ƒ)
        if marketcap_exists: # å¦‚æœåˆ—å­˜åœ¨ï¼Œå°è¯•æœ€ä¼˜æŸ¥è¯¢
            try:
                cursor.execute("SELECT pe_ratio, marketcap FROM MNSPP WHERE symbol = ?", (symbol,))
                row = cursor.fetchone()
                if row:
                    data['pe_ratio'] = row[0]
                    data['marketcap'] = row[1]
                if is_tracing: log_detail(f"[{symbol}] æ­¥éª¤4: å°è¯•ä»MNSPPè·å–PEå’Œå¸‚å€¼ã€‚æŸ¥è¯¢ç»“æœ: PE={data['pe_ratio']}, å¸‚å€¼={data['marketcap']}")
            except sqlite3.OperationalError as e:
                if "no such column: marketcap" in str(e):
                    if i == 0: # åªåœ¨ç¬¬ä¸€æ¬¡é‡åˆ°é”™è¯¯æ—¶æ‰“å°è­¦å‘Š
                        print(f"è­¦å‘Š: MNSPPè¡¨ä¸­æœªæ‰¾åˆ° 'marketcap' åˆ—ã€‚å°†å›é€€åˆ°ä»…æŸ¥è¯¢ 'pe_ratio'ã€‚")
                    marketcap_exists = False # æ ‡è®°åˆ—ä¸å­˜åœ¨ï¼Œåç»­å¾ªç¯ä¸å†å°è¯•
                    # æ‰§è¡Œå›é€€æŸ¥è¯¢
                    cursor.execute("SELECT pe_ratio FROM MNSPP WHERE symbol = ?", (symbol,))
                    row = cursor.fetchone()
                    if row:
                        data['pe_ratio'] = row[0]
                    if is_tracing: log_detail(f"[{symbol}] æ­¥éª¤4 (å›é€€): 'marketcap'åˆ—ä¸å­˜åœ¨ã€‚æŸ¥è¯¢PEã€‚ç»“æœ: PE={data['pe_ratio']}")
                else:
                    # å…¶ä»–æ•°æ®åº“é”™è¯¯
                    print(f"è­¦å‘Š: æŸ¥è¯¢MNSPPè¡¨æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ for {symbol}: {e}")
        else: # å¦‚æœå·²ç»çŸ¥é“åˆ—ä¸å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨å›é€€æŸ¥è¯¢
            cursor.execute("SELECT pe_ratio FROM MNSPP WHERE symbol = ?", (symbol,))
            row = cursor.fetchone()
            if row:
                data['pe_ratio'] = row[0]
            if is_tracing: log_detail(f"[{symbol}] æ­¥éª¤4 (å·²çŸ¥åˆ—ä¸å­˜åœ¨): æŸ¥è¯¢PEã€‚ç»“æœ: PE={data['pe_ratio']}")

        cursor.execute("SELECT price FROM Earning WHERE name = ? AND date = ?", (symbol, data['latest_er_date_str']))
        row = cursor.fetchone()
        data['earning_record_price'] = row[0] if row else None
        if is_tracing: log_detail(f"[{symbol}] æ­¥éª¤5: ä»Earningè¡¨è·å–æœ€æ–°è´¢æŠ¥è®°å½•çš„ä»·æ ¼ã€‚ç»“æœ: {data['earning_record_price']}")
        
        # 5. å¦‚æœæ‰€æœ‰å…³é”®æ•°æ®éƒ½è·å–æˆåŠŸï¼Œåˆ™æ ‡è®°ä¸ºæœ‰æ•ˆ
        data['is_valid'] = True
        cache[symbol] = data
        if is_tracing: log_detail(f"[{symbol}] æˆåŠŸ: æ•°æ®ç¼“å­˜æ„å»ºå®Œæˆï¼Œæ ‡è®°ä¸ºæœ‰æ•ˆã€‚")

    conn.close()
    print(f"--- æ•°æ®ç¼“å­˜æ„å»ºå®Œæˆï¼Œæœ‰æ•ˆæ•°æ®: {len(cache)} ä¸ª ---")
    return cache

# --- 5. ç­–ç•¥æ¨¡å— (å·²é›†æˆè¿½è¸ªç³»ç»Ÿ) ---

def run_strategy_1(data, symbol_to_trace, log_detail):
    """ç­–ç•¥ 1ï¼šæœ€æ–°æ”¶ç›˜ä»·æ¯”è¿‡å»Næ¬¡è´¢æŠ¥çš„æœ€ä½å€¼è¿˜ä½è‡³å°‘7%"""
    prices = data['all_er_prices'][:CONFIG["NUM_EARNINGS_TO_CHECK"]]
    threshold = 1 - CONFIG["MIDDLE_DROP_PERCENTAGE"]
    result = data['latest_price'] < min(prices) * threshold

    if data.get('symbol') == symbol_to_trace:
        log_detail(f"\n--- [{symbol_to_trace}] ç­–ç•¥ 1 è¯„ä¼° ---")
        min_price = min(prices)
        threshold_price = min_price * threshold
        log_detail(f"  - è§„åˆ™: æœ€æ–°æ”¶ç›˜ä»· < è¿‡å»{CONFIG['NUM_EARNINGS_TO_CHECK']}æ¬¡è´¢æŠ¥æœ€ä½ä»· * (1 - {CONFIG['MIDDLE_DROP_PERCENTAGE']})")
        log_detail(f"  - æ¡ä»¶: latest_price ({data['latest_price']}) < min({prices}) ({min_price}) * {threshold:.2f} ({threshold_price:.4f})")
        log_detail(f"  - ç»“æœ: {result}")
        
    return result

# <<< ä¿®æ”¹å¼€å§‹: ä¿®æ”¹ç­–ç•¥3çš„å‡½æ•°ç­¾åå’Œå†…éƒ¨é€»è¾‘ >>>
def run_strategy_3(data, cursor, symbol_sector_map, symbols_for_time_condition, symbol_to_trace, log_detail):
    """ ç­–ç•¥ 3 (ä¿®æ”¹å):
    (1) å¦‚æœæœ€è¿‘2æ¬¡è´¢æŠ¥ä¸Šå‡ï¼Œæœ€æ–°ä»· < è¿‡å»Næ¬¡è´¢æŠ¥æœ€é«˜ä»· * (1-9%)
    (2) å¦‚æœä¸ä¸Šå‡ï¼Œæœ€è¿‘2æ¬¡è´¢æŠ¥å·®é¢ >= 3%ï¼Œæœ€æ–°è´¢æŠ¥éè´Ÿï¼Œä¸”æœ€æ–°ä»· < è¿‡å»Næ¬¡è´¢æŠ¥æœ€ä½ä»·
    ---
    (3) å¿…é¡»æ»¡è¶³(1)æˆ–(2)å…¶ä¸­ä¹‹ä¸€
    (4) å¿…é¡»æ»¡è¶³ï¼šæœ€æ–°ä»·æ¯”å‰10å¤©æœ€ä½ä»·é«˜ä¸è¶…è¿‡3%
    (5) å¿…é¡»æ»¡è¶³ï¼š(åœ¨æŒ‡å®šçš„è´¢æŠ¥æ–‡ä»¶åˆ—è¡¨ä¸­) æˆ– (æœ€æ–°äº¤æ˜“æ—¥è½åœ¨ä¸‹æ¬¡ç†è®ºè´¢æŠ¥å‰6-26å¤©çª—å£æœŸ)
    """
    is_tracing = (data.get('symbol') == symbol_to_trace)
    if is_tracing: log_detail(f"\n--- [{symbol_to_trace}] ç­–ç•¥ 3 è¯„ä¼° (å·²ä¿®æ”¹) ---")

    # æ­¥éª¤1: ä»·æ ¼æ¡ä»¶æ£€æŸ¥ (ä¸Šå‡/éä¸Šå‡åˆ†æ”¯)
    prices = data['all_er_prices'][:CONFIG["NUM_EARNINGS_TO_CHECK"]]
    asc_prices = list(reversed(prices))
    
    price_ok = False
    is_increasing = asc_prices[-2] < asc_prices[-1]
    if is_tracing:
        log_detail(f"  - æœ€è¿‘ä¸¤æ¬¡è´¢æŠ¥ä»· (ä»è¿œåˆ°è¿‘): {[asc_prices[-2], asc_prices[-1]]}")
        log_detail(f"  - æ¡ä»¶ (æœ€è¿‘ä¸¤æ¬¡è´¢æŠ¥ä¸Šå‡): {is_increasing}")

    if is_increasing:
        # ä¸Šå‡åˆ†æ”¯
        threshold = 1 - CONFIG["HIGH_DROP_PERCENTAGE"]
        max_p = max(asc_prices)
        price_ok = data['latest_price'] < max_p * threshold
        if is_tracing:
            log_detail(f"    - åˆ†æ”¯(ä¸Šå‡): latest_price({data['latest_price']}) < max({asc_prices})({max_p}) * {threshold:.2f} ({max_p * threshold:.4f}) -> {price_ok}")
    else:
        # éä¸Šå‡åˆ†æ”¯
        if is_tracing: log_detail(f"    - åˆ†æ”¯(éä¸Šå‡):")
        
        # æ¡ä»¶1: å·®é¢æ£€æŸ¥
        diff_abs = abs(asc_prices[-1] - asc_prices[-2])
        min_diff = asc_prices[-2] * CONFIG["MIN_DROP_PERCENTAGE"]
        diff_ok = diff_abs >= min_diff
        
        # æ–°å¢æ¡ä»¶2: æœ€æ–°è´¢æŠ¥ä¸èƒ½ä¸ºè´Ÿ
        latest_er_positive_ok = data['earning_record_price'] is not None and data['earning_record_price'] > 0
        
        # æ¡ä»¶3: ä½ä»·æ£€æŸ¥
        price_low_ok = data['latest_price'] < min(prices)
        
        # åˆå¹¶æ‰€æœ‰æ¡ä»¶
        price_ok = diff_ok and latest_er_positive_ok and price_low_ok
        
        if is_tracing:
            log_detail(f"      - å·®é¢æ£€æŸ¥: abs({asc_prices[-1]} - {asc_prices[-2]}) ({diff_abs:.4f}) >= {asc_prices[-2]} * {CONFIG['MIN_DROP_PERCENTAGE']} ({min_diff:.4f}) -> {diff_ok}")
            log_detail(f"      - æœ€æ–°è´¢æŠ¥æ£€æŸ¥: Earningè¡¨price({data['earning_record_price']}) > 0 -> {latest_er_positive_ok}")
            log_detail(f"      - ä½ä»·æ£€æŸ¥: latest_price({data['latest_price']}) < min({prices}) ({min(prices)}) -> {price_low_ok}")
            log_detail(f"      - åˆ†æ”¯ç»“æœ: {price_ok}")

    if not price_ok:
        if is_tracing: log_detail(f"  - ç»“æœ: False (ä»·æ ¼æ¡ä»¶æœªæ»¡è¶³)")
        return False

    # æ­¥éª¤2: 10æ—¥æœ€ä½ä»·æ£€æŸ¥
    table_name = symbol_sector_map.get(data['symbol'])
    if not table_name:
        if is_tracing: log_detail(f"      - æ— æ³•æŸ¥è¯¢10æ—¥æœ€ä½ä»· (æ— table_name)ï¼Œç­–ç•¥å¤±è´¥")
        return False
    
    ten_days_ago = data['latest_date'] - datetime.timedelta(days=10)
    cursor.execute(
        f'SELECT MIN(price) FROM "{table_name}" WHERE name = ? AND date BETWEEN ? AND ?',
        (data['symbol'], ten_days_ago.isoformat(), data['latest_date_str'])
    )
    min_price_row = cursor.fetchone()
    min_price_10d = min_price_row[0] if min_price_row and min_price_row[0] is not None else None
    
    if is_tracing: log_detail(f"  - æŸ¥è¯¢è¿‡å»10å¤©æœ€ä½ä»· (ä»{ten_days_ago.isoformat()}åˆ°{data['latest_date_str']}) -> {min_price_10d}")

    if min_price_10d is None:
        if is_tracing: log_detail(f"  - ç»“æœ: False (æœªèƒ½è·å–10æ—¥æœ€ä½ä»·)")
        return False

    threshold_10d = min_price_10d * (1 + CONFIG["MAX_RISE_FROM_7D_LOW"])
    rise_ok = data['latest_price'] <= threshold_10d
    
    if is_tracing:
        log_detail(f"  - æ¡ä»¶ (10æ—¥ä½ä»·ä¸Šæ¶¨å¹…åº¦): latest_price({data['latest_price']}) <= {min_price_10d} * {1 + CONFIG['MAX_RISE_FROM_7D_LOW']} ({threshold_10d:.4f}) -> {rise_ok}")

    if not rise_ok:
        if is_tracing: log_detail(f"  - ç»“æœ: False (10æ—¥ä½ä»·ä¸Šæ¶¨å¹…åº¦æ¡ä»¶æœªæ»¡è¶³)")
        return False

    # æ­¥éª¤3: æ–°å¢çš„æ¡ä»¶æ€§æ—¶é—´çª—å£æ£€æŸ¥
    symbol = data['symbol']
    # ä½¿ç”¨ä¼ å…¥çš„ã€ä¸åŒ…å« 'new' æ–‡ä»¶ symbol çš„åˆ—è¡¨è¿›è¡Œåˆ¤æ–­
    is_in_time_condition_list = symbol in symbols_for_time_condition
    
    next_er = get_next_er_date(data['latest_er_date'])
    window_start = next_er - datetime.timedelta(days=26)
    window_end = next_er - datetime.timedelta(days=6)
    is_in_window = (window_start <= data['latest_date'] <= window_end)

    time_condition_met = is_in_time_condition_list or is_in_window
    
    if is_tracing:
        log_detail(f"  - æ¡ä»¶ (æ—¶é—´çª—å£):")
        log_detail(f"    - æ£€æŸ¥1: æ˜¯å¦åœ¨æŒ‡å®šçš„è´¢æŠ¥æ–‡ä»¶åˆ—è¡¨(ä¸å«new.txt)? -> {is_in_time_condition_list}")
        log_detail(f"    - æ£€æŸ¥2: æ˜¯å¦åœ¨ {window_start} åˆ° {window_end} çš„æ—¶é—´çª—å£å†…? -> {is_in_window}")
        log_detail(f"    - ç»¼åˆæ—¶é—´æ¡ä»¶ (æ»¡è¶³å…¶ä¸€å³å¯): {time_condition_met}")

    # æœ€ç»ˆç»“æœï¼šå¿…é¡»æ»¡è¶³ä»·æ ¼æ¡ä»¶ã€10æ—¥ä½ä»·æ¡ä»¶ï¼Œä»¥åŠæ–°çš„ç»¼åˆæ—¶é—´æ¡ä»¶
    final_result = price_ok and rise_ok and time_condition_met
    
    if is_tracing:
        log_detail(f"  - æœ€ç»ˆç»“æœ (price_ok AND rise_ok AND time_condition_met): {final_result}")
        
    return final_result

# <<< ä¿®æ”¹å¼€å§‹: ä¿®æ”¹ç­–ç•¥3.5çš„å‡½æ•°ç­¾åå’Œå†…éƒ¨é€»è¾‘ >>>
def run_strategy_3_5(data, symbols_for_time_condition, symbol_to_trace, log_detail):
    """ç­–ç•¥ 3.5:
    (1) è¿‡å»2æ¬¡è´¢æŠ¥ä¿æŒä¸Šå‡
    (2) æœ€è¿‘çš„3æ¬¡è´¢æŠ¥é‡Œè‡³å°‘æœ‰ä¸€æ¬¡è´¢æŠ¥çš„æ”¶ç›˜ä»·è¦æ¯”è¯¥symbolçš„æœ€æ–°æ”¶ç›˜ä»·é«˜15%ä»¥ä¸Š
    (3) (åœ¨æŒ‡å®šçš„è´¢æŠ¥æ–‡ä»¶åˆ—è¡¨ä¸­) æˆ– (æœ€æ–°äº¤æ˜“æ—¥è½åœ¨ä¸‹æ¬¡ç†è®ºè´¢æŠ¥å‰6-26å¤©çª—å£æœŸ)
    """
    is_tracing = (data.get('symbol') == symbol_to_trace)
    if len(data['all_er_prices']) < 3 or any(p is None for p in data['all_er_prices'][:3]):
        if is_tracing: log_detail(f"\n--- [{symbol_to_trace}] ç­–ç•¥ 3.5 è¯„ä¼° ---\n  - ç»“æœ: False (è´¢æŠ¥ä»·æ ¼æ•°æ®ä¸è¶³3æ¬¡æˆ–æœ‰ç¼ºå¤±)")
        return False
    
    if is_tracing: log_detail(f"\n--- [{symbol_to_trace}] ç­–ç•¥ 3.5 è¯„ä¼° ---")

    # æ¡ä»¶1: è¿‡å»2æ¬¡è´¢æŠ¥ä¸Šå‡
    prices_n = data['all_er_prices'][:CONFIG["NUM_EARNINGS_TO_CHECK"]]
    asc_prices_n = list(reversed(prices_n))
    is_increasing = asc_prices_n[-2] < asc_prices_n[-1] # åªæ¯”è¾ƒæœ€è¿‘ä¸¤æ¬¡

    # æ¡ä»¶2: ä»·æ ¼é«˜äºé˜ˆå€¼
    prices_3 = data['all_er_prices'][:3]
    price_threshold = data['latest_price'] * (1 + CONFIG["MAX_DROP_PERCENTAGE"])
    any_high = any(p > price_threshold for p in prices_3 if p is not None)

    # æ¡ä»¶3: æ–°å¢çš„æ¡ä»¶æ€§æ—¶é—´çª—å£æ£€æŸ¥
    symbol = data['symbol']
    # ä½¿ç”¨ä¼ å…¥çš„ã€ä¸åŒ…å« 'new' æ–‡ä»¶ symbol çš„åˆ—è¡¨è¿›è¡Œåˆ¤æ–­
    is_in_time_condition_list = symbol in symbols_for_time_condition

    next_er = get_next_er_date(data['latest_er_date'])
    window_start = next_er - datetime.timedelta(days=26)
    window_end = next_er - datetime.timedelta(days=6)
    is_in_window = (window_start <= data['latest_date'] <= window_end)

    time_condition_met = is_in_time_condition_list or is_in_window

    # æœ€ç»ˆç»“æœ
    result = is_increasing and any_high and time_condition_met

    if is_tracing:
        log_detail(f"  - æœ€è¿‘ä¸¤æ¬¡è´¢æŠ¥ä»· (ä»è¿œåˆ°è¿‘): {[asc_prices_n[-2], asc_prices_n[-1]]}")
        log_detail(f"  - æ¡ä»¶1 (æœ€è¿‘ä¸¤æ¬¡è´¢æŠ¥ä¸Šå‡): {is_increasing}")
        log_detail(f"  - æœ€è¿‘ä¸‰æ¬¡è´¢æŠ¥ä»·: {prices_3}")
        log_detail(f"  - æ¡ä»¶2 (ä»»ä¸€ä»·æ¯”æœ€æ–°ä»·é«˜{CONFIG['MAX_DROP_PERCENTAGE']*100}%): any(p > {data['latest_price']} * {1+CONFIG['MAX_DROP_PERCENTAGE']} = {price_threshold:.4f}) -> {any_high}")
        log_detail(f"  - æ¡ä»¶3 (æ—¶é—´çª—å£):")
        log_detail(f"    - æ£€æŸ¥1: æ˜¯å¦åœ¨æŒ‡å®šçš„è´¢æŠ¥æ–‡ä»¶åˆ—è¡¨(ä¸å«new.txt)? -> {is_in_time_condition_list}")
        log_detail(f"    - æ£€æŸ¥2: æ˜¯å¦åœ¨ {window_start} åˆ° {window_end} çš„æ—¶é—´çª—å£å†…? -> {is_in_window}")
        log_detail(f"    - ç»¼åˆæ—¶é—´æ¡ä»¶ (æ»¡è¶³å…¶ä¸€å³å¯): {time_condition_met}")
        log_detail(f"  - æœ€ç»ˆç»“æœ (is_increasing AND any_high AND time_condition_met): {result}")

    return result

# ç­–ç•¥ 4
def run_strategy_4(data, cursor, symbol_sector_map, symbol_to_trace, log_detail):
    """ ç­–ç•¥ 4 (ä¿®æ”¹å):
    (1) æœ€è¿‘Næ¬¡è´¢æŠ¥é€’å¢ï¼Œæœ€è¿‘30å¤©å†…è´¢æŠ¥ï¼ŒEarningè¡¨price>0
    (2) æœ€æ–°æ”¶ç›˜ä»·ä½äºè´¢æŠ¥æ—¥å6-26å¤©
    (3) Aï¼šä»·æ¯”è´¢æŠ¥æ—¥å‰åæœ€é«˜ä»·ä½X%ï¼›Bï¼šæˆ–ä»·æ¯”å€’æ•°ç¬¬äºŒæ¬¡è´¢æŠ¥ä½
    (4) å¿…é¡»æ»¡è¶³ï¼šæœ€æ–°ä»·æ¯”å‰10å¤©æœ€ä½ä»·é«˜ä¸è¶…è¿‡3%
    """
    is_tracing = (data.get('symbol') == symbol_to_trace)
    if is_tracing: log_detail(f"\n--- [{symbol_to_trace}] ç­–ç•¥ 4 è¯„ä¼° (å·²ä¿®æ”¹) ---")

    prices = data['all_er_prices'][:CONFIG["NUM_EARNINGS_TO_CHECK"]]
    asc_prices = list(reversed(prices))
    
    # æ­¥éª¤1: åŸºæœ¬æ¡ä»¶
    is_increasing = all(asc_prices[i] < asc_prices[i+1] for i in range(len(asc_prices)-1))
    
    # ã€ä¿®æ”¹ç‚¹ã€‘å°† datetime.date.today() æ”¹ä¸º data['latest_date']
    # è¿™æ ·åœ¨å›æµ‹ 2023 å¹´çš„æ•°æ®æ—¶ï¼Œå®ƒä¼šåˆ¤æ–­è´¢æŠ¥æ˜¯å¦åœ¨ 2023 å¹´é‚£ä¸ªæ—¶é—´ç‚¹çš„ 30 å¤©å†…
    is_recent_er = data['latest_er_date'] >= (data['latest_date'] - datetime.timedelta(days=30))
    
    is_positive_earning = data['earning_record_price'] is not None and data['earning_record_price'] > 0
    
    if is_tracing:
        log_detail(f"  - è´¢æŠ¥ä»·æ ¼ (ä»è¿œåˆ°è¿‘): {asc_prices}")
        log_detail(f"  - æ¡ä»¶1.1 (é€’å¢): {is_increasing}")
        # ã€ä¿®æ”¹æ—¥å¿—è¾“å‡ºã€‘
        log_detail(f"  - æ¡ä»¶1.2 (ç›¸å¯¹åŸºå‡†æ—¥30å¤©è´¢æŠ¥): {data['latest_er_date']} >= {data['latest_date'] - datetime.timedelta(days=30)} -> {is_recent_er}")
        log_detail(f"  - æ¡ä»¶1.3 (Earningè¡¨price>0): {data['earning_record_price']} > 0 -> {is_positive_earning}")

    if not (is_increasing and is_recent_er and is_positive_earning):
        if is_tracing: log_detail(f"  - ç»“æœ: False (åŸºç¡€æ¡ä»¶æœªæ»¡è¶³)")
        return False

    # æ­¥éª¤2: æ—¥æœŸçª—å£
    window_start = data['latest_er_date'] + datetime.timedelta(days=6)
    window_end = data['latest_er_date'] + datetime.timedelta(days=26)
    is_in_window = (window_start <= data['latest_date'] <= window_end)
    if is_tracing:
        log_detail(f"  - æ—¶é—´çª—å£: {window_start} <= æœ€æ–°äº¤æ˜“æ—¥({data['latest_date']}) <= {window_end}")
        log_detail(f"  - æ¡ä»¶2 (åœ¨æ—¶é—´çª—å£å†…): {is_in_window}")
    
    if not is_in_window:
        if is_tracing: log_detail(f"  - ç»“æœ: False (æœªåœ¨æ—¶é—´çª—å£å†…)")
        return False
        
    # æ­¥éª¤3: A/B æ¡ä»¶åˆ¤æ–­
    initial_price_ok = False
    
    # Bæ¡ä»¶
    second_er_price = data['all_er_prices'][1]
    if second_er_price is None: 
        if is_tracing: log_detail(f"  - ç»“æœ: False (å€’æ•°ç¬¬äºŒæ¬¡è´¢æŠ¥ä»·æ ¼ç¼ºå¤±)")
        return False
    
    cond_B = data['latest_price'] < second_er_price
    if is_tracing: log_detail(f"  - æ¡ä»¶3.B: latest_price({data['latest_price']}) < å€’æ•°ç¬¬äºŒæ¬¡è´¢æŠ¥ä»·({second_er_price}) -> {cond_B}")
    if cond_B: 
        initial_price_ok = True
    else:
        # Aæ¡ä»¶ (ä»…åœ¨Bä¸æ»¡è¶³æ—¶æ£€æŸ¥)
        table_name = symbol_sector_map.get(data['symbol'])
        if not table_name:
            if is_tracing: log_detail(f"  - ç»“æœ: False (æ— æ³•è·å–table_nameä»¥æ£€æŸ¥Aæ¡ä»¶)")
            return False
            
        start_range = data['latest_er_date'] - datetime.timedelta(days=2)
        end_range   = data['latest_er_date'] + datetime.timedelta(days=5)
        cursor.execute(
            f'SELECT MAX(price) FROM "{table_name}" WHERE name = ? AND date BETWEEN ? AND ?',
            (data['symbol'], start_range.isoformat(), end_range.isoformat())
        )
        max_price_row = cursor.fetchone()
        max_price_around_er = max_price_row[0] if max_price_row else None
        
        if max_price_around_er is None: 
            if is_tracing: log_detail(f"  - ç»“æœ: False (æ— æ³•è·å–è´¢æŠ¥æ—¥å‰åæœ€é«˜ä»·)")
            return False

        mcap = data['marketcap']
        drop_pct = CONFIG["MINOR_DROP_PERCENTAGE"] if mcap and mcap >= CONFIG["MARKETCAP_THRESHOLD"] else CONFIG["MIDDLE_PLUS_DROP_PERCENTAGE"]
        threshold_price = max_price_around_er * (1 - drop_pct)
        cond_A = data['latest_price'] < threshold_price
        
        if is_tracing:
            log_detail(f"  - æ¡ä»¶3.A:")
            log_detail(f"    - å¸‚å€¼: {mcap}, é˜ˆå€¼: {CONFIG['MARKETCAP_THRESHOLD']} -> ä½¿ç”¨ä¸‹è·Œç™¾åˆ†æ¯”: {drop_pct}")
            log_detail(f"    - è´¢æŠ¥æ—¥å‰å(-2+5å¤©)æœ€é«˜ä»·: {max_price_around_er}")
            log_detail(f"    - åˆ¤æ–­: latest_price({data['latest_price']}) < {max_price_around_er} * (1-{drop_pct}) ({threshold_price:.4f}) -> {cond_A}")
        
        if cond_A:
            initial_price_ok = True

    if not initial_price_ok:
        if is_tracing: log_detail(f"  - ç»“æœ: False (A/Bä»·æ ¼æ¡ä»¶å‡æœªæ»¡è¶³)")
        return False

    # æ­¥éª¤4: 10æ—¥æœ€ä½ä»·æ£€æŸ¥ (æ–°å¢çš„æœ€ç»ˆæ¡ä»¶)
    table_name = symbol_sector_map.get(data['symbol']) # é‡å¤è·å–ä»¥é˜²ä¸‡ä¸€ï¼Œè™½ç„¶å‰é¢å·²æœ‰
    if not table_name:
        if is_tracing: log_detail(f"      - æ— æ³•æŸ¥è¯¢10æ—¥æœ€ä½ä»· (æ— table_name)ï¼Œç­–ç•¥å¤±è´¥")
        return False
        
    ten_days_ago = data['latest_date'] - datetime.timedelta(days=10)
    cursor.execute(
        f'SELECT MIN(price) FROM "{table_name}" WHERE name = ? AND date BETWEEN ? AND ?',
        (data['symbol'], ten_days_ago.isoformat(), data['latest_date_str'])
    )
    min_price_row = cursor.fetchone()
    min_price_10d = min_price_row[0] if min_price_row and min_price_row[0] is not None else None

    if is_tracing: log_detail(f"  - æŸ¥è¯¢è¿‡å»10å¤©æœ€ä½ä»· (ä»{ten_days_ago.isoformat()}åˆ°{data['latest_date_str']}) -> {min_price_10d}")

    if min_price_10d is None:
        if is_tracing: log_detail(f"  - ç»“æœ: False (æœªèƒ½è·å–10æ—¥æœ€ä½ä»·)")
        return False

    threshold_10d = min_price_10d * (1 + CONFIG["MAX_RISE_FROM_7D_LOW"])
    rise_ok = data['latest_price'] <= threshold_10d

    if is_tracing:
        log_detail(f"  - æ¡ä»¶4 (10æ—¥ä½ä»·ä¸Šæ¶¨å¹…åº¦): latest_price({data['latest_price']}) <= {min_price_10d} * {1 + CONFIG['MAX_RISE_FROM_7D_LOW']} ({threshold_10d:.4f}) -> {rise_ok}")
        log_detail(f"  - æœ€ç»ˆç»“æœ: {rise_ok}")

    return rise_ok

# --- 6. è¿‡æ»¤æ¨¡å— (å·²é›†æˆè¿½è¸ªç³»ç»Ÿ) ---

def get_symbols_with_latest_negative_earning(db_path):
    """
    è·å–æœ€æ–°ä¸€æœŸè´¢æŠ¥ä¸ºè´Ÿ (price < 0) çš„æ‰€æœ‰ symbol é›†åˆã€‚
    è¿™å–ä»£äº†åŸå…ˆçš„â€œæœ€è¿‘30å¤©â€é€»è¾‘ã€‚
    """
    conn = sqlite3.connect(db_path, timeout=60.0)
    cursor = conn.cursor()
    
    # ä½¿ç”¨çª—å£å‡½æ•° ROW_NUMBER æ¥ä¸ºæ¯ä¸ª symbol çš„è´¢æŠ¥æŒ‰æ—¥æœŸé™åºæ’åã€‚
    # rn = 1 å°±ä»£è¡¨æ˜¯æœ€æ–°çš„ä¸€æœŸè´¢æŠ¥ã€‚
    # ç„¶åæˆ‘ä»¬åªç­›é€‰å‡ºé‚£äº›æœ€æ–°è´¢æŠ¥ price < 0 çš„ symbolã€‚
    query = """
    SELECT name
    FROM (
        SELECT
            name,
            price,
            ROW_NUMBER() OVER(PARTITION BY name ORDER BY date DESC) as rn
        FROM Earning
    )
    WHERE rn = 1 AND price < 0;
    """
    
    try:
        cursor.execute(query)
        symbols = {row[0] for row in cursor.fetchall()}
        print(f"\nè¿‡æ»¤æ¡ä»¶: æ‰¾åˆ° {len(symbols)} ä¸ªæœ€æ–°ä¸€æœŸè´¢æŠ¥ä¸ºè´Ÿçš„ symbolã€‚")
    except sqlite3.OperationalError as e:
        print(f"é”™è¯¯: æŸ¥è¯¢æœ€æ–°è´Ÿè´¢æŠ¥æ—¶å‘ç”Ÿæ•°æ®åº“é”™è¯¯: {e}")
        print("è¿™å¯èƒ½æ˜¯å› ä¸ºæ‚¨çš„ SQLite ç‰ˆæœ¬ä¸æ”¯æŒçª—å£å‡½æ•°ã€‚å°†è¿”å›ç©ºé›†åˆã€‚")
        symbols = set()
        
    conn.close()
    return symbols

def apply_filters(symbols_set, stock_data_cache, blacklist, negative_earnings_set, is_main_list, symbol_to_trace, log_detail):
    """å¯¹ç»™å®šçš„symbolé›†åˆåº”ç”¨ä¸€ç³»åˆ—è¿‡æ»¤è§„åˆ™"""
    final_list = []
    for symbol in sorted(list(symbols_set)):
        is_tracing = (symbol == symbol_to_trace)
        if is_tracing: log_detail(f"\n{'='*20} å¼€å§‹å¯¹ç›®æ ‡ {symbol} è¿›è¡Œè¿‡æ»¤ (åˆ—è¡¨: {'ä¸»åˆ—è¡¨' if is_main_list else 'é€šçŸ¥åˆ—è¡¨'}) {'='*20}")

        if symbol not in stock_data_cache or not stock_data_cache[symbol]['is_valid']:
            if is_tracing: log_detail(f"[{symbol}] è¿‡æ»¤: å› ä¸ºåœ¨æ•°æ®ç¼“å­˜ä¸­æ— æ•ˆæˆ–ä¸å­˜åœ¨ã€‚")
            continue
        
        data = stock_data_cache[symbol]

        # è¿‡æ»¤1: é»‘åå•
        if symbol in blacklist:
            if is_tracing: log_detail(f"[{symbol}] è¿‡æ»¤(é»‘åå•): symbolåœ¨é»‘åå•ä¸­ã€‚")
            continue
        elif is_tracing: log_detail(f"[{symbol}] é€šè¿‡(é»‘åå•): symbolä¸åœ¨é»‘åå•ä¸­ã€‚")

        # æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šæ­¤å¤„çš„ negative_earnings_set ç°åœ¨æ˜¯â€œæœ€æ–°è´¢æŠ¥ä¸ºè´Ÿâ€çš„é›†åˆ
        if is_main_list and symbol in negative_earnings_set:
            if is_tracing: log_detail(f"[{symbol}] è¿‡æ»¤(ä¸»åˆ—è¡¨-æœ€æ–°è´¢æŠ¥ä¸ºè´Ÿ): symbolåœ¨æœ€æ–°è´Ÿè´¢æŠ¥é›†åˆä¸­ã€‚")
            continue
        elif is_tracing and is_main_list: log_detail(f"[{symbol}] é€šè¿‡(ä¸»åˆ—è¡¨-æœ€æ–°è´¢æŠ¥ä¸ºè´Ÿ): symbolä¸åœ¨æœ€æ–°è´Ÿè´¢æŠ¥é›†åˆä¸­ã€‚")

        # è¿‡æ»¤3: æˆäº¤é¢
        turnover = data['latest_price'] * data['latest_volume']
        if turnover < CONFIG["MIN_TURNOVER"]:
            if is_tracing: log_detail(f"[{symbol}] è¿‡æ»¤(æˆäº¤é¢): {turnover:,.0f} < {CONFIG['MIN_TURNOVER']:,}")
            continue
        elif is_tracing: log_detail(f"[{symbol}] é€šè¿‡(æˆäº¤é¢): {turnover:,.0f} >= {CONFIG['MIN_TURNOVER']:,}")

        pe = data['pe_ratio']
        if pe is None or str(pe).strip().lower() in ("--", "null", ""):
            if is_tracing: log_detail(f"[{symbol}] è¿‡æ»¤(PEæ— æ•ˆ): PEå€¼ä¸º '{pe}'ã€‚")
            continue
        elif is_tracing: log_detail(f"[{symbol}] é€šè¿‡(PEæœ‰æ•ˆ): PEå€¼ä¸º '{pe}'ã€‚")

        # è¿‡æ»¤5: æœ€æ–°äº¤æ˜“æ—¥ == æœ€æ–°è´¢æŠ¥æ—¥
        if data['latest_date_str'] == data['latest_er_date_str']:
            if is_tracing: log_detail(f"[{symbol}] è¿‡æ»¤(æ—¥æœŸç›¸åŒ): æœ€æ–°äº¤æ˜“æ—¥({data['latest_date_str']}) ä¸ æœ€æ–°è´¢æŠ¥æ—¥({data['latest_er_date_str']}) ç›¸åŒã€‚")
            continue
        elif is_tracing: log_detail(f"[{symbol}] é€šè¿‡(æ—¥æœŸä¸åŒ)ã€‚")
            
        final_list.append(symbol)
        if is_tracing: log_detail(f"[{symbol}] æˆåŠŸ: é€šè¿‡æ‰€æœ‰è¿‡æ»¤å™¨ï¼Œå·²æ·»åŠ åˆ°æœ€ç»ˆåˆ—è¡¨ã€‚")
        
    return final_list

# ========== æ–°å¢/ä¿®æ”¹éƒ¨åˆ† 2/2 ==========
def run_processing_logic(log_detail):
    """
    æ ¸å¿ƒå¤„ç†é€»è¾‘ã€‚
    è¿™ä¸ªå‡½æ•°åŒ…å«äº†æ‰€æœ‰çš„æ•°æ®åŠ è½½ã€ç­–ç•¥æ‰§è¡Œã€è¿‡æ»¤å’Œæ–‡ä»¶è¾“å‡ºã€‚
    """
    log_detail(f"ç¨‹åºå¼€å§‹è¿è¡Œ...")
    if TARGET_DATE:
        log_detail(f"\nâš ï¸âš ï¸âš ï¸ æ³¨æ„ï¼šå½“å‰å¤„äºã€å›æµ‹æ¨¡å¼ã€‘ï¼Œç›®æ ‡æ—¥æœŸï¼š{TARGET_DATE} âš ï¸âš ï¸âš ï¸")
        log_detail("ä¸ºäº†ä¿æŠ¤ç°æœ‰æ•°æ®ï¼Œæœ¬æ¬¡è¿è¡Œå°†ã€ä¸ä¼šã€‘æ›´æ–°ä»»ä½• JSON æˆ–å¤‡ä»½æ–‡ä»¶ã€‚\n")
    
    # 1. åŠ è½½åˆå§‹æ•°æ®
    # ä¿®æ”¹ï¼šåŠ è½½å¤–éƒ¨æ ‡ç­¾é…ç½®å¹¶æ›´æ–°CONFIG
    tag_blacklist_from_file, hot_tags_from_file = load_tag_settings(TAGS_SETTING_JSON_FILE)
    CONFIG["BLACKLIST_TAGS"] = tag_blacklist_from_file
    CONFIG["HOT_TAGS"] = hot_tags_from_file
    
    # æ–°å¢: ä» Blacklist.json åŠ è½½ Earning Symbol é»‘åå•
    CONFIG["SYMBOL_BLACKLIST"] = load_earning_symbol_blacklist(BLACKLIST_JSON_FILE)
    
    symbol_sector_map = create_symbol_to_sector_map(SECTORS_JSON_FILE)
    if not symbol_sector_map:
        log_detail("é”™è¯¯: æ— æ³•åŠ è½½æ¿å—æ˜ å°„ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        return

    # æ–°å¢ï¼šåŠ è½½ symbol->tags æ˜ å°„
    symbol_to_tags_map = load_symbol_tags(DESCRIPTION_JSON_FILE)

    # <<< ä¿®æ”¹å¼€å§‹: åˆ†ç¦»å¤„ç† 'new' æ–‡ä»¶å’Œå…¶ä»–è´¢æŠ¥æ–‡ä»¶ >>>
    # åŠ è½½ 'new' æ–‡ä»¶ä¸­çš„ symbols
    symbols_from_new_file = set(get_symbols_from_file(PATHS["earnings_release_new"](news_path)))
    log_detail(f"ä» earnings_release_new.txt åŠ è½½äº† {len(symbols_from_new_file)} ä¸ª symbolã€‚")

    # åŠ è½½å…¶ä»–æ–‡ä»¶ä¸­çš„ symbolsï¼Œè¿™äº›å°†ç”¨äºæ»¡è¶³ç­–ç•¥ä¸­çš„â€œæ—¶é—´æ¡ä»¶â€
    symbols_next = get_symbols_from_file(PATHS["earnings_release_next"](news_path))
    symbols_third = get_symbols_from_file(PATHS["earnings_release_third"](news_path))
    symbols_fourth = get_symbols_from_file(PATHS["earnings_release_fourth"](news_path))
    symbols_fifth = get_symbols_from_file(PATHS["earnings_release_fifth"](news_path))
    # ä½¿ç”¨é›†åˆå»é‡
    symbols_for_time_condition = set(symbols_next + symbols_third + symbols_fourth + symbols_fifth)
    log_detail(f"ä»å…¶ä»–è´¢æŠ¥æ–‡ä»¶ (next, third, fourth, fifth) åŠ è½½äº† {len(symbols_for_time_condition)} ä¸ªä¸é‡å¤çš„ symbolã€‚")

    # åˆå§‹æ–‡ä»¶ä¸­çš„æ‰€æœ‰ symbol (ç”¨äºå†³å®šæ€»å…±è¦å¤„ç†å“ªäº›ä»æ–‡ä»¶æ¥çš„ symbol)
    # ä½¿ç”¨é›†åˆçš„å¹¶é›†æ“ä½œ `|`
    initial_symbols_all = list(symbols_from_new_file | symbols_for_time_condition)

    if SYMBOL_TO_TRACE and SYMBOL_TO_TRACE in initial_symbols_all:
        log_detail(f"\nè¿½è¸ªä¿¡æ¯: {SYMBOL_TO_TRACE} åœ¨åˆå§‹æ–‡ä»¶åˆ—è¡¨ä¸­ã€‚")
        if SYMBOL_TO_TRACE in symbols_from_new_file:
             log_detail(f"  - å…·ä½“æ¥æº: {SYMBOL_TO_TRACE} åœ¨ 'new' æ–‡ä»¶ä¸­ï¼Œå°†ä¸æ»¡è¶³ç­–ç•¥3/3.5çš„æ—¶é—´æ¡ä»¶ã€‚")
        if SYMBOL_TO_TRACE in symbols_for_time_condition:
             log_detail(f"  - å…·ä½“æ¥æº: {SYMBOL_TO_TRACE} åœ¨å…¶ä»–è´¢æŠ¥æ–‡ä»¶ä¸­ï¼Œå°†æ»¡è¶³ç­–ç•¥3/3.5çš„æ—¶é—´æ¡ä»¶ã€‚")
    elif SYMBOL_TO_TRACE:
        log_detail(f"\nè¿½è¸ªä¿¡æ¯: {SYMBOL_TO_TRACE} ä¸åœ¨ä»»ä½•åˆå§‹è´¢æŠ¥æ–‡ä»¶ä¸­ã€‚")

    with sqlite3.connect(DB_FILE, timeout=60.0) as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT DISTINCT name FROM Earning")
        all_db_symbols = [row[0] for row in cursor.fetchall()]

    # symbols_to_process ç°åœ¨åŒ…å«æ‰€æœ‰æ¥è‡ªè´¢æŠ¥æ–‡ä»¶å’Œæ•°æ®åº“çš„ symbol
    symbols_to_process = sorted(list(set(initial_symbols_all + all_db_symbols)))
    # <<< ä¿®æ”¹ç»“æŸ >>>

    # 1.1 (æ–°å¢) åº”ç”¨ SYMBOL_BLACKLIST è¿›è¡Œåˆæ­¥è¿‡æ»¤
    symbol_blacklist = CONFIG.get("SYMBOL_BLACKLIST", set())
    if symbol_blacklist:
        original_count = len(symbols_to_process)
        removed_symbols = set(symbols_to_process) & symbol_blacklist
        
        if removed_symbols:
            log_detail(f"\n--- åº”ç”¨ Symbol é»‘åå• ---")
            log_detail(f"ä»å¤„ç†åˆ—è¡¨ä¸­ç§»é™¤äº† {len(removed_symbols)} ä¸ªåœ¨é»‘åå•ä¸­çš„ symbol: {sorted(list(removed_symbols))}")
            if SYMBOL_TO_TRACE and SYMBOL_TO_TRACE in removed_symbols:
                log_detail(f"è¿½è¸ªä¿¡æ¯: ç›®æ ‡ symbol '{SYMBOL_TO_TRACE}' åœ¨ Symbol é»‘åå•ä¸­ï¼Œå·²è¢«ç§»é™¤ï¼Œå°†ä¸ä¼šè¢«å¤„ç†ã€‚")

        symbols_to_process = [s for s in symbols_to_process if s not in symbol_blacklist]
        log_detail(f"Symbol åˆ—è¡¨ä» {original_count} ä¸ªç¼©å‡åˆ° {len(symbols_to_process)} ä¸ªã€‚")
    
    # 2. æ„å»ºæ•°æ®ç¼“å­˜ (æ ¸å¿ƒæ€§èƒ½æå‡)
    stock_data_cache = build_stock_data_cache(symbols_to_process, DB_FILE, symbol_sector_map, SYMBOL_TO_TRACE, log_detail, target_date=TARGET_DATE)

    # 3. è¿è¡Œç­–ç•¥
    results = defaultdict(list)
    with sqlite3.connect(DB_FILE, timeout=60.0) as conn: # ç­–ç•¥3å’Œ4éœ€è¦ä¸€ä¸ªcursor
        cursor = conn.cursor()

        for symbol, data in stock_data_cache.items():
            if not data['is_valid']:
                continue
            
            data['symbol'] = symbol # å°†symbolæœ¬èº«åŠ å…¥dataï¼Œæ–¹ä¾¿ç­–ç•¥3ã€4ä½¿ç”¨

            # <<< ä¿®æ”¹å¼€å§‹: ä½¿ç”¨ 'symbols_for_time_condition' æ¥å†³å®šæ˜¯å¦è¿è¡Œç­–ç•¥1 >>>
            # è·‘ä¸»åˆ—è¡¨ç­–ç•¥ (ä»…é’ˆå¯¹åœ¨ 'next', 'third' ç­‰æ–‡ä»¶é‡Œçš„symbols)
            if symbol in symbols_for_time_condition:
                if run_strategy_1(data, SYMBOL_TO_TRACE, log_detail): results['s1'].append(symbol)
            # <<< ä¿®æ”¹ç»“æŸ >>>
                
            # <<< ä¿®æ”¹å¼€å§‹: å°† 'symbols_for_time_condition' ä¼ é€’ç»™ç­–ç•¥3å’Œ3.5 >>>
            # è·‘é€šçŸ¥åˆ—è¡¨ç­–ç•¥ (é’ˆå¯¹æ‰€æœ‰æœ‰æ•°æ®çš„symbols)
            if run_strategy_3(data, cursor, symbol_sector_map, symbols_for_time_condition, SYMBOL_TO_TRACE, log_detail): results['s3'].append(symbol)
            if run_strategy_3_5(data, symbols_for_time_condition, SYMBOL_TO_TRACE, log_detail): results['s3_5'].append(symbol)
            # <<< ä¿®æ”¹ç»“æŸ >>>
            if run_strategy_4(data, cursor, symbol_sector_map, SYMBOL_TO_TRACE, log_detail): results['s4'].append(symbol)

    # 4. æ±‡æ€»åˆæ­¥ç»“æœ
    # ä¸»åˆ—è¡¨ç°åœ¨åªåŒ…å« s1
    s1_set  = set(results['s1'])
    prelim_final_symbols = s1_set

    prelim_Strategy34_list = set(results['s3'] + results['s3_5'] + results['s4'])

    log_detail("\n--- ç­–ç•¥è¿è¡Œåˆæ­¥ç»“æœ ---")
    log_detail(f"ä¸»åˆ—è¡¨åˆæ­¥å€™é€‰: {len(prelim_final_symbols)} ä¸ª")
    log_detail(f"é€šçŸ¥åˆ—è¡¨åˆæ­¥å€™é€‰: {len(prelim_Strategy34_list)} ä¸ª")
    if SYMBOL_TO_TRACE and SYMBOL_TO_TRACE in prelim_final_symbols:
        log_detail(f"è¿½è¸ªä¿¡æ¯: {SYMBOL_TO_TRACE} åœ¨ç­–ç•¥ç­›é€‰åçš„ 'ä¸»åˆ—è¡¨' åˆæ­¥å€™é€‰åå•ä¸­ã€‚")
    if SYMBOL_TO_TRACE and SYMBOL_TO_TRACE in prelim_Strategy34_list:
        log_detail(f"è¿½è¸ªä¿¡æ¯: {SYMBOL_TO_TRACE} åœ¨ç­–ç•¥ç­›é€‰åçš„ 'é€šçŸ¥åˆ—è¡¨' åˆæ­¥å€™é€‰åå•ä¸­ã€‚")

    # 5. åº”ç”¨é€šç”¨è¿‡æ»¤å™¨
    blacklist = load_blacklist(BLACKLIST_JSON_FILE)
    negative_earnings_set = get_symbols_with_latest_negative_earning(DB_FILE)

    log_detail("\n--- å¼€å§‹å¯¹ä¸»åˆ—è¡¨è¿›è¡Œè¿‡æ»¤ ---")
    # å¯¹ s1 ç”¨è´Ÿè´¢æŠ¥è¿‡æ»¤
    log_detail("\n--- å¼€å§‹å¯¹ s1 åˆ—è¡¨è¿›è¡Œè¿‡æ»¤ï¼ˆåŒ…å«è´Ÿè´¢æŠ¥è¿‡æ»¤ï¼‰ ---")
    final_s1 = apply_filters(
        s1_set,
        stock_data_cache,
        blacklist,
        negative_earnings_set,  # è¿™é‡Œä¼ å…¥çœŸå®çš„è´Ÿè´¢æŠ¥é›†åˆ
        True,
        SYMBOL_TO_TRACE,
        log_detail
    )

    # æœ€ç»ˆä¸»åˆ—è¡¨ç›´æ¥ç­‰äº final_s1
    final_symbols = final_s1
    
    log_detail("\n--- å¼€å§‹å¯¹é€šçŸ¥åˆ—è¡¨è¿›è¡Œè¿‡æ»¤ ---")
    final_Strategy34_list = apply_filters(prelim_Strategy34_list, stock_data_cache, blacklist, set(), False, SYMBOL_TO_TRACE, log_detail)

    # åœ¨è¿™é‡ŒåŠ ä¸€è¡Œï¼šæŠŠå‡ºç°åœ¨ä¸»åˆ—è¡¨é‡Œçš„å‰”é™¤æ‰
    final_Strategy34_list = [s for s in final_Strategy34_list if s not in final_symbols]

    # 6. åŸºäºTagçš„è¿‡æ»¤ (åœ¨æ‰€æœ‰å…¶ä»–è¿‡æ»¤ä¹‹å)
    log_detail("\n--- å¼€å§‹åŸºäºTagçš„è¿‡æ»¤ ---")
    tag_blacklist = CONFIG["BLACKLIST_TAGS"]
    log_detail(f"Tagé»‘åå•: {tag_blacklist}")

    # è¿‡æ»¤ä¸»åˆ—è¡¨
    filtered_final_symbols = []
    for symbol in final_symbols:
        symbol_tags = set(symbol_to_tags_map.get(symbol, []))
        if not symbol_tags.intersection(tag_blacklist):
            filtered_final_symbols.append(symbol)
        else:
            log_detail(f"  - [ä¸»åˆ—è¡¨] å› Tagè¢«è¿‡æ»¤: {symbol} (Tags: {list(symbol_tags)})")
    final_symbols = filtered_final_symbols

    # è¿‡æ»¤é€šçŸ¥åˆ—è¡¨
    filtered_Strategy34_list = []
    for symbol in final_Strategy34_list:
        symbol_tags = set(symbol_to_tags_map.get(symbol, []))
        if not symbol_tags.intersection(tag_blacklist):
            filtered_Strategy34_list.append(symbol)
        else:
            log_detail(f"  - [é€šçŸ¥åˆ—è¡¨] å› Tagè¢«è¿‡æ»¤: {symbol} (Tags: {list(symbol_tags)})")
    final_Strategy34_list = filtered_Strategy34_list

    # 7. æ–°å¢ï¼šæ ¹æ® panel.json ä¸­å·²å­˜åœ¨çš„åˆ†ç»„è¿›è¡Œæœ€ç»ˆè¿‡æ»¤ (ç§»æ¤è‡ª b.py)
    log_detail("\n--- å¼€å§‹æ ¹æ® panel.json å·²æœ‰åˆ†ç»„ ('Today', 'Must') è¿›è¡Œæœ€ç»ˆè¿‡æ»¤ ---")
    try:
        with open(PANEL_JSON_FILE, 'r', encoding='utf-8') as f:
            panel_data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        log_detail(f"è­¦å‘Š: panel æ–‡ä»¶ ({PANEL_JSON_FILE}) æœªæ‰¾åˆ°æˆ–æ ¼å¼é”™è¯¯ï¼Œå°†ä¸è¿›è¡Œåˆ†ç»„è¿‡æ»¤ã€‚")
        panel_data = {}

    # è·å– 'Today' å’Œ 'Must' åˆ†ç»„ä¸­çš„æ‰€æœ‰ symbolï¼Œå¹¶åˆå¹¶æˆä¸€ä¸ªé›†åˆç”¨äºè¿‡æ»¤
    # .get(key, {}) æ˜¯ä¸€ç§å®‰å…¨çš„æ–¹å¼ï¼Œå¦‚æœåˆ†ç»„ä¸å­˜åœ¨ï¼Œä¼šè¿”å›ä¸€ä¸ªç©ºå­—å…¸ï¼Œé¿å…å‡ºé”™
    symbols_in_today = set(panel_data.get('Today', {}).keys())
    symbols_in_must = set(panel_data.get('Must', {}).keys())
    
    # ä½¿ç”¨é›†åˆçš„å¹¶é›†æ“ä½œ `|` æ¥åˆå¹¶ä¸¤ä¸ªé›†åˆ
    exclusion_symbols = symbols_in_today | symbols_in_must

    log_detail(f"ä» panel.json åŠ è½½äº† {len(symbols_in_today)} ä¸ª 'Today' symbolã€‚")
    log_detail(f"ä» panel.json åŠ è½½äº† {len(symbols_in_must)} ä¸ª 'Must' symbolã€‚")
    log_detail(f"åˆå¹¶åçš„æ’é™¤åˆ—è¡¨åŒ…å« {len(exclusion_symbols)} ä¸ªä¸é‡å¤çš„ symbolã€‚")

    # è¿‡æ»¤ Strategy12 åˆ—è¡¨ (final_symbols)
    # è§„åˆ™: å¦‚æœ symbol åœ¨ 'Today' æˆ– 'Must' ç»„ä¸­ï¼Œåˆ™ç§»é™¤
    final_symbols_before_panel_filter = final_symbols
    final_symbols = [s for s in final_symbols if s not in exclusion_symbols]
    removed_from_s12 = set(final_symbols_before_panel_filter) - set(final_symbols)
    if removed_from_s12:
        log_detail(f"  - [Strategy12 è¿‡æ»¤]: ç§»é™¤äº† {len(removed_from_s12)} ä¸ªå·²å­˜åœ¨äº 'Today' æˆ– 'Must' ç»„çš„ symbol: {sorted(list(removed_from_s12))}")

    # è¿‡æ»¤ Strategy34 åˆ—è¡¨ (final_Strategy34_list)
    # è§„åˆ™: å¦‚æœ symbol åœ¨ 'Today' æˆ– 'Must' ç»„ä¸­ï¼Œåˆ™ç§»é™¤
    final_Strategy34_list_before_panel_filter = final_Strategy34_list
    final_Strategy34_list = [s for s in final_Strategy34_list if s not in exclusion_symbols]
    removed_from_s34 = set(final_Strategy34_list_before_panel_filter) - set(final_Strategy34_list)
    if removed_from_s34:
        log_detail(f"  - [Strategy34 è¿‡æ»¤]: ç§»é™¤äº† {len(removed_from_s34)} ä¸ªå·²å­˜åœ¨äº 'Today' æˆ– 'Must' ç»„çš„ symbol: {sorted(list(removed_from_s34))}")
    # ==================== ä»£ç ä¿®æ”¹ç»“æŸ ====================

    # 8. ç”Ÿæˆæ ‡æ³¨å¹¶è¾“å‡ºæœ€ç»ˆç»“æœ
    # 8.1 çƒ­é—¨Tagå‘½ä¸­ -> JSONä¸­æ ‡æ³¨ â€œ{symbol}çƒ­â€
    hot_tags = set(CONFIG.get("HOT_TAGS", set()))
    def build_symbol_note_map(symbols):
        note_map = {}
        for sym in symbols:
            tags = set(symbol_to_tags_map.get(sym, []))
            if tags & hot_tags:
                note_map[sym] = f"{sym}çƒ­"
            else:
                note_map[sym] = ""
        return note_map

    strategy12_notes = build_symbol_note_map(final_symbols)
    strategy34_notes = build_symbol_note_map(final_Strategy34_list)

    # [å›æµ‹ç§»æ¤ï¼šå®‰å…¨æ‹¦æˆª]
    if TARGET_DATE:
        log_detail("\n" + "="*60)
        log_detail(f"ğŸ›‘ [å®‰å…¨æ‹¦æˆª] å›æµ‹æ¨¡å¼å·²å¯ç”¨ã€‚ä»¥ä¸‹æ“ä½œå·²å–æ¶ˆï¼š")
        log_detail(f"   - å†™å…¥ {os.path.basename(PANEL_JSON_FILE)}")
        log_detail(f"   - å†™å…¥ {os.path.basename(EARNING_HISTORY_JSON_FILE)}")
        log_detail(f"   - æ›´æ–°å¤‡ä»½ TXT æ–‡ä»¶")
        log_detail("-" * 40)
        # ã€ä¿®æ­£å˜é‡åã€‘å°† final_s1 æ”¹ä¸º final_symbols
        log_detail(f"ğŸ“Š [æ¨¡æ‹Ÿç»“æœ] Strategy12: {len(final_symbols)} ä¸ª, Strategy34: {len(final_Strategy34_list)} ä¸ª")
        if SYMBOL_TO_TRACE:
            log_detail(f"ğŸ” [éªŒè¯] '{SYMBOL_TO_TRACE}' çŠ¶æ€: S12={SYMBOL_TO_TRACE in final_symbols}, S34={SYMBOL_TO_TRACE in final_Strategy34_list}")
        log_detail("="*60 + "\n")
        return 
    
    # 8.2 æ‰“å°æœ€ç»ˆç»“æœ
    log_detail("\n--- æ‰€æœ‰è¿‡æ»¤å®Œæˆåçš„æœ€ç»ˆç»“æœ ---")
    log_detail(f"ä¸»åˆ—è¡¨(Strategy12)æœ€ç»ˆæ•°é‡: {len(final_symbols)} - {final_symbols}")
    log_detail(f"é€šçŸ¥åˆ—è¡¨(Strategy34)æœ€ç»ˆæ•°é‡: {len(final_Strategy34_list)} - {final_Strategy34_list}")
    if SYMBOL_TO_TRACE:
        if SYMBOL_TO_TRACE in removed_from_s12:
            log_detail(f"\næœ€ç»ˆè¿½è¸ªç»“æœ: {SYMBOL_TO_TRACE} é€šè¿‡äº†ç­–ç•¥ç­›é€‰ï¼Œä½†å› å·²å­˜åœ¨äº 'Today' æˆ– 'Must' ç»„è€Œæœªè¢«åŠ å…¥ 'Strategy12'ã€‚")
        elif SYMBOL_TO_TRACE in removed_from_s34:
            log_detail(f"\næœ€ç»ˆè¿½è¸ªç»“æœ: {SYMBOL_TO_TRACE} é€šè¿‡äº†ç­–ç•¥ç­›é€‰ï¼Œä½†å› å·²å­˜åœ¨äº 'Today' æˆ– 'Must' ç»„è€Œæœªè¢«åŠ å…¥ 'Strategy34'ã€‚")
        elif SYMBOL_TO_TRACE in final_symbols:
            log_detail(f"\næœ€ç»ˆè¿½è¸ªç»“æœ: {SYMBOL_TO_TRACE} æˆåŠŸè¿›å…¥äº†æœ€ç»ˆçš„ 'Strategy12' åˆ—è¡¨ã€‚")
        elif SYMBOL_TO_TRACE in final_Strategy34_list:
            log_detail(f"\næœ€ç»ˆè¿½è¸ªç»“æœ: {SYMBOL_TO_TRACE} æˆåŠŸè¿›å…¥äº†æœ€ç»ˆçš„ 'Strategy34' åˆ—è¡¨ã€‚")
        else:
            log_detail(f"\næœ€ç»ˆè¿½è¸ªç»“æœ: {SYMBOL_TO_TRACE} æœªè¿›å…¥ä»»ä½•æœ€ç»ˆåˆ—è¡¨ã€‚")

    # 8.3 æ–‡ä»¶å’ŒJSONè¾“å‡º
    # ä¸»åˆ—è¡¨ (Strategy12)
    update_json_panel(final_symbols, PANEL_JSON_FILE, "Strategy12", symbol_to_note=strategy12_notes)
    # >>> ä¿®æ”¹ç‚¹ 1: åŒæ­¥å†™å…¥ Strategy12_backup <<<
    update_json_panel(final_symbols, PANEL_JSON_FILE, "Strategy12_backup", symbol_to_note=strategy12_notes)
    
    try:
        backup_path = PATHS["backup_Strategy12"](news_path)
        os.makedirs(os.path.dirname(backup_path), exist_ok=True)

        with open(backup_path, 'w', encoding='utf-8') as f:
            for sym in sorted(final_symbols):
                f.write(sym + '\n')
        print(f"ä¸»åˆ—è¡¨å¤‡ä»½å·²æ›´æ–°: {backup_path}")

    except IOError as e:
        print(f"å†™å…¥ä¸»åˆ—è¡¨æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    # é€šçŸ¥åˆ—è¡¨ (Strategy34)
    update_json_panel(final_Strategy34_list, PANEL_JSON_FILE, "Strategy34", symbol_to_note=strategy34_notes)
    # >>> ä¿®æ”¹ç‚¹ 2: åŒæ­¥å†™å…¥ Strategy34_backup <<<
    update_json_panel(final_Strategy34_list, PANEL_JSON_FILE, "Strategy34_backup", symbol_to_note=strategy34_notes)
    
    try:
        backup_path = PATHS["backup_Strategy34"](news_path)
        os.makedirs(os.path.dirname(backup_path), exist_ok=True)

        with open(backup_path, 'w', encoding='utf-8') as f:
            for sym in sorted(final_Strategy34_list):
                f.write(sym + '\n')
        print(f"é€šçŸ¥åˆ—è¡¨å¤‡ä»½å·²æ›´æ–°: {backup_path}")

    except IOError as e:
        print(f"å†™å…¥é€šçŸ¥åˆ—è¡¨æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    # ========== æ–°å¢æ­¥éª¤ 9: æ›´æ–° Earning_History.json ==========
    # åˆå¹¶æ‰€æœ‰æœ€ç»ˆç¬¦åˆæ¡ä»¶çš„ symbol (ä¸»åˆ—è¡¨ + é€šçŸ¥åˆ—è¡¨)
    all_final_symbols = sorted(list(set(final_symbols + final_Strategy34_list)))
    
    if all_final_symbols:
        update_earning_history_json(
            EARNING_HISTORY_JSON_FILE,
            "season",  # a.py å†™å…¥ 'season' åˆ†ç»„
            all_final_symbols,
            log_detail
        )
    else:
        log_detail("\n--- æ— ç¬¦åˆæ¡ä»¶çš„ symbol å¯å†™å…¥ Earning_History.json ---")
    # ==========================================================

# --- 7. ä¸»æ‰§è¡Œæµç¨‹ (å·²é›†æˆè¿½è¸ªç³»ç»Ÿ) ---

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†è¿½è¸ªç¬¦å·
    if SYMBOL_TO_TRACE:
        # å¦‚æœè®¾ç½®äº†ï¼Œåˆ™å¯ç”¨æ–‡ä»¶æ—¥å¿—è®°å½•
        print(f"è¿½è¸ªæ¨¡å¼å·²å¯ç”¨ï¼Œç›®æ ‡: {SYMBOL_TO_TRACE}ã€‚æ—¥å¿—å°†å†™å…¥: {LOG_FILE_PATH}")
        try:
            with open(LOG_FILE_PATH, 'w', encoding='utf-8') as log_file:
                def log_detail_file(message):
                    """ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºå°†è°ƒè¯•ä¿¡æ¯å†™å…¥æ–‡ä»¶å¹¶æ‰“å°åˆ°æ§åˆ¶å°"""
                    log_file.write(message + '\n')
                    print(message)
                
                # è°ƒç”¨æ ¸å¿ƒé€»è¾‘ï¼Œå¹¶ä¼ å…¥æ–‡ä»¶æ—¥å¿—è®°å½•å‡½æ•°
                run_processing_logic(log_detail_file)

        except IOError as e:
            print(f"é”™è¯¯ï¼šæ— æ³•æ‰“å¼€æˆ–å†™å…¥æ—¥å¿—æ–‡ä»¶ {LOG_FILE_PATH}: {e}")
    
    else:
        # å¦‚æœæ²¡æœ‰è®¾ç½®ï¼Œåˆ™åªåœ¨æ§åˆ¶å°æ‰“å°ä¿¡æ¯
        print("è¿½è¸ªæ¨¡å¼æœªå¯ç”¨ (SYMBOL_TO_TRACE ä¸ºç©º)ã€‚å°†ä¸ä¼šç”Ÿæˆæ—¥å¿—æ–‡ä»¶ã€‚")
        def log_detail_console(message):
            """ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œå½“ä¸è¿½è¸ªæ—¶åªæ‰“å°åˆ°æ§åˆ¶å°"""
            print(message)
        
        # è°ƒç”¨æ ¸å¿ƒé€»è¾‘ï¼Œå¹¶ä¼ å…¥ä»…æ§åˆ¶å°æ‰“å°çš„å‡½æ•°
        run_processing_logic(log_detail_console)

    print("\nç¨‹åºè¿è¡Œç»“æŸã€‚")

if __name__ == "__main__":
    main()